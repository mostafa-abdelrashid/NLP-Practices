{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06e2b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline # type: ignore\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "gen_text = generator(\"Hello, I'm a Football Fan,\", max_length=100, num_return_sequences=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "749ca64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I'm a Football Fan, my name is Eric, I'm a Free agent and I'm a 10-year-old boy from Chicago, who has never played football before this season. I don't know why you're saying that, but I think it's because you're a very good football player. I'm proud of your accomplishments, you've done a lot of things for this organization and your teammates, the fans, the coaches, the players, the fans. I think you're a very good football player.\n",
      "\n",
      "\"But I also think you're an NFL team, a great team to be around. I think you're a great team and I think you're a great person to be around, a great person to play with, to be a part of. I think you're a great person to be around and I think you're a great person to be around, too.\n",
      "\n",
      "\"It's just a matter of being able to see the other guys and how you're doing. You're a very good person, you're a great person. And I think you're a great person, but I think you're a great person to be around, too. So that's the motivation for me.\"\n",
      "\n",
      "The Packers will also look to add a veteran safety in the draft\n"
     ]
    }
   ],
   "source": [
    "generated_text = gen_text[0]['generated_text']\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110f2cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I think you're a very good football player. I'm proud of your accomplishments, you've done a lot of things for this organization and your teammates, the fans, the coaches, the players,\" says 10-year-old Eric. The Packers will also look to add a veteran safety.\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summarized_text = summarizer(generated_text, max_length=130, min_length=30, do_sample=False)\n",
    "print(summarized_text[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5b9cba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I think you're a very good football player. I'm proud of your accomplishments, you've done a lot of things for this organization and your teammates, the fans, the coaches, the players,\" says 10-year-old Eric. The Packers will also look to add a veteran safety.\n"
     ]
    }
   ],
   "source": [
    "summarized_text = summarized_text[0]['summary_text']\n",
    "print(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee819286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mm174\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cpu\n",
      "Your input_length: 66 is bigger than 0.9 * max_length: 40. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "« Je pense que vous êtes un très bon joueur de football. Je suis fier de vos réalisations, vous avez fait beaucoup de choses pour cette organisation et vos coéquipiers, les fans, les\n"
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "translated_text =  translator(summarized_text, max_length=40)[0]['translation_text']\n",
    "print(translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19074e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: You're a very good person, you're a great person\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util # type: ignore\n",
    "\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "content =  generated_text\n",
    "question = \"What is the main topic of the text?\"\n",
    "\n",
    "sentences = [sentence.strip() for sentence in content.split('.') if sentence.strip()]\n",
    "\n",
    "question_embedding = model.encode(question, convert_to_tensor=True)\n",
    "sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "best_match_idx = util.cos_sim(question_embedding, sentence_embeddings).argmax().item()\n",
    "print(f\"Answer: {sentences[best_match_idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d6681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
