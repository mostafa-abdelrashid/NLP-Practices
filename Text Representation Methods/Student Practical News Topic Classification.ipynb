{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea8e19e-8ea2-4f12-aac2-1d707a601220",
   "metadata": {
    "id": "1ea8e19e-8ea2-4f12-aac2-1d707a601220"
   },
   "source": [
    "# Task: News Topic Classification with AG News\n",
    "\n",
    "## Objective\n",
    "Classify **news articles** into 4 categories (*World, Sports, Business, Sci/Tech*) using different **text representation methods**.\n",
    "\n",
    "<small>[AG News Classification Dataset on Kaggle](https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset)</small>\n",
    "    \n",
    "---\n",
    "\n",
    "## Step 1: Data Preparation\n",
    "- Load the **AG News dataset** (train.csv & test.csv).  \n",
    "- Combine the **title + description** into one text field.  \n",
    "- Apply **basic preprocessing**:\n",
    "  - Lowercase  \n",
    "  - Remove symbols/punctuation  \n",
    "  - Try stopwords removal or stemming â†’ compare results  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f393f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552070eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df3de7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index  ...                                        Description\n",
       "0            3  ...  Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1            3  ...  Reuters - Private investment firm Carlyle Grou...\n",
       "2            3  ...  Reuters - Soaring crude prices plus worries\\ab...\n",
       "3            3  ...  Reuters - Authorities have halted oil export\\f...\n",
       "4            3  ...  AFP - Tearaway world oil prices, toppling reco...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a6ee71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index  ...                                        Description\n",
       "0            3  ...  Unions representing workers at Turner   Newall...\n",
       "1            4  ...  SPACE.com - TORONTO, Canada -- A second\\team o...\n",
       "2            4  ...  AP - A company founded by a chemistry research...\n",
       "3            4  ...  AP - It's barely dawn when Mike Fitzpatrick st...\n",
       "4            4  ...  AP - Southern California's smog-fighting agenc...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e288de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Title_Description'] = df_train['Title'] + \" \" + df_train['Description']\n",
    "df_test['Title_Description'] = df_test['Title'] + \" \" + df_test['Description']\n",
    "df_train.drop(columns=['Title', 'Description'], inplace=True)\n",
    "df_test.drop(columns=['Title', 'Description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b4e2fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title_Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                  Title_Description\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reute...\n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...\n",
       "2            3  Oil and Economy Cloud Stocks' Outlook (Reuters...\n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...\n",
       "4            3  Oil prices soar to all-time record, posing new..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e3747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts , train_labels =shuffle(df_train.Title_Description,df_train['Class Index'],random_state=42)\n",
    "test_texts , test_labels =shuffle(df_test.Title_Description,df_test['Class Index'],random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "945077c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts=train_texts[:7000]\n",
    "train_labels=train_labels[:7000]\n",
    "test_texts=test_texts[:2000]\n",
    "test_labels=test_labels[:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "456c410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fc08d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_stop_words(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    words=[word for word in words if word not in stopwords.words('english')]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce451997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_stemmer(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    stemmer=PorterStemmer()\n",
    "    words=[stemmer.stem(word) for word in words ]\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e67ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_stemmed = [text_preprocessing_stemmer(sent) for sent in train_texts]\n",
    "train_texts_stop_words = [text_preprocessing_stop_words(sent) for sent in train_texts]\n",
    "test_texts_stemmed = [text_preprocessing_stemmer(sent) for sent in test_texts]\n",
    "test_texts_stop_words = [text_preprocessing_stop_words(sent) for sent in test_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72c1c7",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2: Representations to Try\n",
    "You must implement **all 5 methods** below:\n",
    "\n",
    "1. **Bag of Words (BoW)**  \n",
    "   - Represent each text as a count of words.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c89fa33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4801b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_stemmed = CountVectorizer()\n",
    "bow_stop_words = CountVectorizer()\n",
    "\n",
    "X_train_stemmed_bow  = bow_stemmed.fit_transform(train_texts_stemmed)\n",
    "X_train_stop_words_bow  = bow_stop_words.fit_transform(train_texts_stop_words)\n",
    "X_test_stemmed_bow  = bow_stemmed.transform(test_texts_stemmed)\n",
    "X_test_stop_words_bow  = bow_stop_words.transform(test_texts_stop_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85510f4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "2. **TF-IDF**  \n",
    "   - Apply TF-IDF weighting instead of raw counts.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2b1b0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_stemmed = TfidfVectorizer()\n",
    "tf_idf_stop_words = TfidfVectorizer()\n",
    "\n",
    "X_train_stemmed_tfidf  = tf_idf_stemmed.fit_transform(train_texts_stemmed)\n",
    "X_train_stop_words_tfidf  = tf_idf_stop_words.fit_transform(train_texts_stop_words)\n",
    "X_test_stemmed_tfidf  = tf_idf_stemmed.transform(test_texts_stemmed)\n",
    "X_test_stop_words_tfidf  = tf_idf_stop_words.transform(test_texts_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ea7c0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "3. **N-grams (Bi/Tri-grams)**  \n",
    "   - Use bigrams and trigrams to capture context.   \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01e58ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_stemmed = CountVectorizer(ngram_range=(1,2))\n",
    "ngram_stop_words = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "X_train_stemmed_ngram  = ngram_stemmed.fit_transform(train_texts_stemmed)\n",
    "X_train_stop_words_ngram  = ngram_stop_words.fit_transform(train_texts_stop_words)\n",
    "X_test_stemmed_ngram  = ngram_stemmed.transform(test_texts_stemmed)\n",
    "X_test_stop_words_ngram  = ngram_stop_words.transform(test_texts_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab4024",
   "metadata": {},
   "source": [
    "4. **Word2Vec (Pretrained)**  \n",
    "   - Use pretrained embeddings (e.g., GoogleNews vectors).  \n",
    "   - Convert each document into a vector (average word embeddings).  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c1c76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-wiki-gigaword-200\")\n",
    "def text_to_vector(text):\n",
    "    words = word_tokenize(text)\n",
    "    vectors = []\n",
    "    for word in words:\n",
    "        if word in model:\n",
    "            vectors.append(model[word])\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "858d76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stemmed_word2vec =  np.array([text_to_vector(sent) for sent in train_texts_stemmed])\n",
    "X_test_stemmed_word2vec =  np.array([text_to_vector(sent) for sent in test_texts_stemmed])\n",
    "X_train_stop_words_word2vec =  np.array([text_to_vector(sent) for sent in train_texts_stop_words])\n",
    "X_test_stop_words_word2vec =  np.array([text_to_vector(sent) for sent in test_texts_stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c89e5",
   "metadata": {},
   "source": [
    "  \n",
    "5. **Doc2Vec**  \n",
    "   - Train your own Doc2Vec model on the dataset.  \n",
    "   - Represent each document with its vector.  \n",
    "   \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f7ebe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import  TaggedDocument\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a8a90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tagged_documents(texts):\n",
    "    tagged_docs = []\n",
    "    for i, text in enumerate(texts):\n",
    "        words = simple_preprocess(text)\n",
    "        tagged_docs.append(TaggedDocument(words, [i]))\n",
    "    return tagged_docs\n",
    "X_train_stemmed_tagged = prepare_tagged_documents(train_texts_stemmed)\n",
    "X_test_stemmed_tagged = prepare_tagged_documents(test_texts_stemmed)\n",
    "X_train_stop_words_tagged = prepare_tagged_documents(train_texts_stop_words)\n",
    "X_test_stop_words_tagged = prepare_tagged_documents(test_texts_stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "057c43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(\n",
    "    vector_size=300,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    epochs=20)\n",
    "model.build_vocab(X_train_stemmed_tagged +   X_train_stop_words_tagged  )\n",
    "model.train(X_train_stemmed_tagged +  X_train_stop_words_tagged , total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40a0f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc2vec_vector(model, tagged_docs):\n",
    "    vectors = []\n",
    "    for doc in tagged_docs:\n",
    "        vector = model.infer_vector(doc.words)\n",
    "        vectors.append(vector)\n",
    "    return np.array(vectors)\n",
    "X_train_stemmed_doc2vec = get_doc2vec_vector(model, X_train_stemmed_tagged)\n",
    "X_test_stemmed_doc2vec = get_doc2vec_vector(model, X_test_stemmed_tagged)\n",
    "X_train_stop_words_doc2vec = get_doc2vec_vector(model, X_train_stop_words_tagged)\n",
    "X_test_stop_words_doc2vec = get_doc2vec_vector(model, X_test_stop_words_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f04b202",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Try Two Classifiers\n",
    "For **each text representation method**, train **two different models** and compare:\n",
    "\n",
    "- **Logistic Regression**\n",
    "- **Naive Bayes** (or any other model of your choice, e.g., SVM, Decision Tree)\n",
    "\n",
    "Hint:  \n",
    "- Logistic Regression usually performs well on sparse features (BoW, TF-IDF, N-grams).  \n",
    "- Naive Bayes is very fast and works surprisingly well for text classification.  \n",
    "- Compare their accuracy for each representation.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8cb632",
   "metadata": {},
   "source": [
    "- **Logistic Regression**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98d7c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e355b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW stemmed\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_stemmed_bow, train_labels)\n",
    "preds = clf.predict(X_test_stemmed_bow)\n",
    "accuracies['BOW Stemmed'] = accuracy_score(test_labels, preds)\n",
    "# BOW stop words\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_stop_words_bow, train_labels)\n",
    "preds = clf.predict(X_test_stop_words_bow)\n",
    "accuracies['BOW Stop Words'] = accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d328b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf stemmed\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_stemmed_tfidf, train_labels)\n",
    "preds = clf.predict(X_test_stemmed_tfidf)\n",
    "accuracies['tf_idf Stemmed'] = accuracy_score(test_labels, preds)\n",
    "# tf_idf stop words\n",
    "clf= LogisticRegression()\n",
    "clf.fit(X_train_stop_words_tfidf, train_labels)\n",
    "preds = clf.predict(X_test_stop_words_tfidf)\n",
    "accuracies['tf_idf Stop Words'] = accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a82a5412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   ngram stemmed\n",
    "clf= LogisticRegression()\n",
    "clf.fit(X_train_stemmed_ngram, train_labels)\n",
    "preds = clf.predict(X_test_stemmed_ngram)\n",
    "accuracies['ngram Stemmed'] = accuracy_score(test_labels, preds)\n",
    "#   ngram stop words\n",
    "clf= LogisticRegression()\n",
    "clf.fit(X_train_stop_words_ngram, train_labels)\n",
    "preds = clf.predict(X_test_stop_words_ngram)\n",
    "accuracies['ngram Stop Words'] = accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95c2755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mm174\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec stemmed\n",
    "clf.fit(X_train_stemmed_word2vec, train_labels)\n",
    "preds = clf.predict(X_test_stemmed_word2vec)\n",
    "accuracies['Word2Vec Stemmed'] = accuracy_score(test_labels, preds)\n",
    "# Word2Vec stop words\n",
    "clf.fit(X_train_stop_words_word2vec, train_labels)\n",
    "preds = clf.predict(X_test_stop_words_word2vec)\n",
    "accuracies['Word2Vec Stop Words'] = accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3de1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec stemmed\n",
    "clf.fit(X_train_stemmed_doc2vec, train_labels)\n",
    "preds = clf.predict(X_test_stemmed_doc2vec)\n",
    "accuracies['Doc2Vec Stemmed'] = accuracy_score(test_labels, preds)\n",
    "# Doc2Vec stop words\n",
    "clf.fit(X_train_stop_words_doc2vec, train_labels)\n",
    "preds = clf.predict(X_test_stop_words_doc2vec)\n",
    "accuracies['Doc2Vec Stop Words'] = accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6e124",
   "metadata": {},
   "source": [
    "- **Naive Bayes** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea196355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "accuracies2 = {}\n",
    "# BOW stemmed\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_stemmed_bow, train_labels)\n",
    "preds = clf.predict(X_test_stemmed_bow)\n",
    "accuracies2['BOW Stemmed NB'] = accuracy_score(test_labels, preds)\n",
    "# BOW stop words\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_stop_words_bow, train_labels)\n",
    "preds = clf.predict(X_test_stop_words_bow)\n",
    "accuracies2['BOW Stop Words NB'] = accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3c01ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf stemmed\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_stemmed_tfidf, train_labels)\n",
    "preds = clf.predict(X_test_stemmed_tfidf)\n",
    "accuracies2['tf_idf Stemmed NB'] = accuracy_score(test_labels, preds)\n",
    "# tf_idf stop words\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_stop_words_tfidf, train_labels)\n",
    "preds = clf.predict(X_test_stop_words_tfidf)\n",
    "accuracies2['tf_idf Stop Words NB'] = accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "004ca265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram stemmed\n",
    "clf= MultinomialNB()\n",
    "clf.fit(X_train_stemmed_ngram, train_labels)\n",
    "preds= clf.predict(X_test_stemmed_ngram)\n",
    "accuracies2['ngram Stemmed NB'] = accuracy_score(test_labels, preds)\n",
    "# ngram stop words\n",
    "clf= MultinomialNB()\n",
    "clf.fit(X_train_stop_words_ngram, train_labels)\n",
    "preds= clf.predict(X_test_stop_words_ngram)\n",
    "accuracies2['ngram Stop Words NB'] = accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5c9b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec stemmed\n",
    "clf= GaussianNB()\n",
    "clf.fit(X_train_stemmed_word2vec, train_labels)\n",
    "preds = clf.predict(X_test_stemmed_word2vec)\n",
    "accuracies2['Word2Vec Stemmed'] = accuracy_score(test_labels, preds)\n",
    "# Word2Vec stop words\n",
    "clf.fit(X_train_stop_words_word2vec, train_labels)\n",
    "preds = clf.predict(X_test_stop_words_word2vec)\n",
    "accuracies2['Word2Vec Stop Words'] = accuracy_score(test_labels, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0168aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec stemmed\n",
    "clf= GaussianNB()\n",
    "clf.fit(X_train_stemmed_doc2vec, train_labels)\n",
    "preds = clf.predict(X_test_stemmed_doc2vec)\n",
    "accuracies2['Doc2Vec Stemmed'] = accuracy_score(test_labels, preds)\n",
    "# Doc2Vec stop words\n",
    "clf.fit(X_train_stop_words_doc2vec, train_labels)\n",
    "preds = clf.predict(X_test_stop_words_doc2vec)\n",
    "accuracies2['Doc2Vec Stop Words'] = accuracy_score(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dac71884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracies:\n",
      "\n",
      "BOW Stemmed: 0.8675\n",
      "BOW Stop Words: 0.8655\n",
      "tf_idf Stemmed: 0.8805\n",
      "tf_idf Stop Words: 0.8795\n",
      "ngram Stemmed: 0.8720\n",
      "ngram Stop Words: 0.8790\n",
      "Word2Vec Stemmed: 0.8655\n",
      "Word2Vec Stop Words: 0.8875\n",
      "Doc2Vec Stemmed: 0.8005\n",
      "Doc2Vec Stop Words: 0.7725\n",
      "------------------------------\n",
      "\n",
      "Naive Bayes Accuracies:\n",
      "\n",
      "BOW Stemmed NB: 0.8875\n",
      "BOW Stop Words NB: 0.8830\n",
      "tf_idf Stemmed NB: 0.8845\n",
      "tf_idf Stop Words NB: 0.8805\n",
      "ngram Stemmed NB: 0.8860\n",
      "ngram Stop Words NB: 0.8895\n",
      "Word2Vec Stemmed: 0.8325\n",
      "Word2Vec Stop Words: 0.8650\n",
      "Doc2Vec Stemmed: 0.7595\n",
      "Doc2Vec Stop Words: 0.7410\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Accuracies:\\n\")\n",
    "for key, value in accuracies.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "print(\"-\"*30+'\\n')\n",
    "\n",
    "print(\"Naive Bayes Accuracies:\\n\")\n",
    "for key, value in accuracies2.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14763c8",
   "metadata": {},
   "source": [
    "\n",
    "## Step 4: Results Table\n",
    "\n",
    "For Stemmed Words dataframe:\n",
    "\n",
    "| Representation | Logistic Regression Acc | Naive Bayes Acc | Notes |\n",
    "|----------------|--------------------------|-----------------|-------|\n",
    "| BoW            |           0.8675         |      0.8875     |       |\n",
    "| TF-IDF         |           0.8805         |      0.8845     |       |\n",
    "| N-grams        |           0.8720         |      0.8860     |       |\n",
    "| Word2Vec       |           0.8325         |      0.8325     |       |\n",
    "| Doc2Vec        |           0.8005         |      0.7595     |       |\n",
    "---\n",
    "\n",
    "For removed Stop words dataframe:\n",
    "\n",
    "| Representation | Logistic Regression Acc | Naive Bayes Acc | Notes |\n",
    "|----------------|--------------------------|-----------------|-------|\n",
    "| BoW            |          0.8655          |     0.8830      |       |\n",
    "| TF-IDF         |          0.8795          |     0.8805      |       |\n",
    "| N-grams        |          0.8790          |     0.8895      |       |\n",
    "| Word2Vec       |          0.8650          |     0.8650      |       |\n",
    "| Doc2Vec        |          0.7725          |     0.7410      |       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff288e",
   "metadata": {},
   "source": [
    "\n",
    "## Reflection Questions\n",
    "1. Which method gave the best accuracy? Why?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec67d5e1",
   "metadata": {},
   "source": [
    "    BoW with the Naive Bayes Classifier & Stemmed Words df , Because the dataset is relatively small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb934251",
   "metadata": {},
   "source": [
    "2. Did N-grams improve performance compared to BoW? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f420b6",
   "metadata": {},
   "source": [
    "    Yes But just with the Logistic regression clf , the opposite happened with the naive bayes clf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcced10",
   "metadata": {},
   "source": [
    " \n",
    "3. How do pretrained embeddings (Word2Vec) compare to TF-IDF?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7a2af",
   "metadata": {},
   "source": [
    "    Word2vec is worse compared with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5066ff",
   "metadata": {},
   "source": [
    "4. Which method is more efficient in terms of speed and memory? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a7e44",
   "metadata": {},
   "source": [
    "    Bow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d1bb3",
   "metadata": {},
   "source": [
    " \n",
    "5. If you had to build a **real news classifier**, which method would you choose and why?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef1fe6",
   "metadata": {},
   "source": [
    "    Word2vec with pretrained model like google news "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
